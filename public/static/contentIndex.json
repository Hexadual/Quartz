{"Blog-Posts/50-More-terabytes":{"slug":"Blog-Posts/50-More-terabytes","filePath":"Blog Posts/50 More terabytes.md","title":"50 More terabytes","links":[],"tags":[],"content":"4/23/2025\nTLDR: Over the Summer I managed to buy 10 more hard drives (WD Red Plus’s). Each one was 10TB and was going to be installed into my NAS. This was a much needed upgrade as I was completely out of storage\n\nPart 1: The RAID\nIn the middle pod I added 5 more hard drives, each one was 10 Terabytes for a total raw addition of 50 terabytes. However, due to redundancy this is not how much space I was able to get back. In that pod of 5 I configured the system to allow for 1 drive to fail and still retail all the data that is stored across the 5 drives. So the total usable space is 40 Terabytes of usable space. This is all possible due to a cool technology called a RAID (Redundant Array of Independent Disks.) and an operating system called TrueNAS.\n\nFigure 1: The New five hard drives installed in the middle pod of the NAS Chassis\n\nPart 2: Airflow\nThe fun was not over that easily! After finishing everything that needed to be done I cleaned up the server and put it back on the rack and all was well. Until about 30 minuets later when I realized that the new RAID performance was extremely worse than what was expected. After digging around I saw that the new drives that were installed were running at 65 degrees (149F). For reference the recommended temperature of a hard drive is 5 to 50 degrees. After googling that fact I realized that I forgot to install the fan in the front of the new hard drives. There was no fan that was blowing fresh air over the drives to cool them. Which is why they were 15 degrees over temperature. After I installed the fan the temps were able to drop all the way down to 45 degrees (113F)\n\nFigure 2: Hard Drive temps before and after the cooling fan\nSo morale of the story is to always install fans in a server."},"Blog-Posts/Accessing-all-my-files-from-every-device":{"slug":"Blog-Posts/Accessing-all-my-files-from-every-device","filePath":"Blog Posts/Accessing all my files from every device.md","title":"Accessing all my files from every device","links":[],"tags":[],"content":"6/19/2025\nTLDR: I used Synching to backup and sync all my files across 3 states and 4 devices.\n\nWHY?\nIn the modern world everyone relies on things like Google Drive, Microsoft OneDrive and to a lesser extent iCloud to be able to access files when they need them. For me I didn’t like the idea of using something like OneDrive to store all of the documents that I was working on for school. I wanted to be able to access my projects even when I was offline. Because of this I needed to have the files on my computer. However this posed a new question. If I were to start something on my laptop and then come home from class I would need to transfer it to my desktop to keep working on it. I need something to Sync the files between my devices. Upon first thought the solution is to simply install Syncthing on my laptop and desktop then boom problem solved. Well not exactly.  for Syncthing to work both devices need to be awake to talk to each other. This means that I still need to get my laptop out when I get home and then let it connect to my PC and then once its done I can put it away. So I needed to get more creative.\n\nHOW?\nThe solution that I came up with is to have a server running Syncthing that is always accessible on a VM in my homelab. Then on all of the devices that need to access my files they connect to the server and constantly synchronize what I am working on to the server. When one of my devices comes online it gets the latest changes and new files. This allows me to work on something in class on my laptop in the morning. Then when I get home form class my work is already in the Syncthing server. So when I turn on my PC it automatically gets the work from the server. I don’t even need to take my laptop out of my backpack.\n\nImage 1: My Syncthing implantation diagram.\nClients\nSynctrazor Synctrazor V2 is a great tool that runs Syncthing in the windows tray on startup.\nSyncthing Tray Is also another client that does the same thing and works on Linux.\n\nOther cool configurations\nPicking what Files get synced\nMy laptop only has 500GB of storage so I don’t want all the files that are on my desktop to get sent to my laptop. So what I did was configure Syncthing so that only my school folder and my pictures folder got synced to my laptop. On my gaming computer It only synced my video’s folder for game recordings and pictures for screenshots.\n\nImage 2: My PCs Syncthing panel\n\n321 BACKUP\nOne fun extra perk of using a central Syncthing server is it also acts as a central point for a backup server. For my implementation I followed the 321 backup method.\n\n\n                  \n                  Quote\n                  \n                \n\n\n\nThree Copies: This includes your original data and two separate backup copies.\nTwo Different Media: This means storing your backups on different types of storage, such as a hard drive and cloud storage, or a server and an external drive.\nOne Off-site Copy: This ensures that one backup is stored in a physically separate location from your primary data and other backups, protecting against site-specific disasters like fires or floods\n\n\n\n\nThree Copies: I have three copies of my data. One on my PC, one on the Syncthing server, and the third is on the offsite backup server that my Syncthing server backs up to.\nTwo Different Media: For two different media, all of the storage for the Syncthing and the off site backup servers are in a RAID5 configuration as well as on different systems.\nOne Off-site Copy: My Syncthing server stores all of its data on a NAS that is in my homelab. Every night that NAS backs up a copy of itself to another NAS that I have at a different location.\n\nSyncthing has become such a seamless part of my daily life that I often forget it’s even there. Quietly running in the background, it keeps my files synced across my devices without me even thinking about it."},"Blog-Posts/Covid-Epoch-Time":{"slug":"Blog-Posts/Covid-Epoch-Time","filePath":"Blog Posts/Covid Epoch Time.md","title":"Covid Epoch Time","links":[],"tags":[],"content":"6/24/2025\nTDLR: I made a website that tracks the seconds since the day school shut down for COVID-19 in Illinois.\n\nMy friends and I recently realized we’ve been keeping track of the time in our lives by how long its been since the COVID-19 school shutdowns in 2020. That instantly brought the UNIX epoch timestamp to mind, so an hour later, the COVID Epoch Timestamp was born.\n\nTime.Hexadual.io\n\n\nUPDATE: 8/30/25\nI have also added a counter at the bottom for the 2038 Overflow. aka the Epochalypse. This is caused when a system is using a 32 bit integer to store Unix time. The latest time a 32 bit integer can sore is 231 − 1 = (2,147,483,647) or 03:14:07 UTC on 19 January 2038.\n\nAlso check out more time formatting and storage bugs"},"Blog-Posts/Stop-link-rot-with-Linkwarden":{"slug":"Blog-Posts/Stop-link-rot-with-Linkwarden","filePath":"Blog Posts/Stop link rot with Linkwarden.md","title":"Stop link rot with Linkwarden","links":[],"tags":[],"content":"9/22/2025\nTLDR: Linkwarden preserves your bookmarks into its database so that even if its deleted you still have a copy.\n\nclp.law.harvard.edu/knowledge-hub/magazine/issues/the-evolution-of-law-libraries/pausing-the-internet/\nwww.techpowerup.com/326107/anandtech-shuts-down-an-icon-of-tech-news-and-reviews-rides-into-the-sunset\nwww.thefpsreview.com/2025/08/02/anandtechs-archives-disappear-without-a-trace/\nwww.npr.org/2025/01/26/nx-s1-5271539/the-internet-is-forever-or-is-it"},"Blog":{"slug":"Blog","filePath":"Blog.md","title":"Blog","links":["Blog-Posts/Covid-Epoch-Time","Blog-Posts/Accessing-all-my-files-from-every-device","Blog-Posts/50-More-terabytes"],"tags":[],"content":"I’m always working on something!\n\nCovid Epoch Time\n6/24/2025\nTrack the passage of time since the start of the COVID-19 pandemic\n\nAccessing all my files from every device\n6/19/2025\nI made a solution that allows me to access all my files anywhere without using the cloud.\n\nAdding 50 more Terabytes to my NAS\n4/23/2025\nOver the Summer I bought more hard drives for the NAS."},"Homelab-Posts/Automation--and--Scripting":{"slug":"Homelab-Posts/Automation--and--Scripting","filePath":"Homelab Posts/Automation & Scripting.md","title":"Automation & Scripting","links":[],"tags":[],"content":"Tock Archivist\n9/18/2025\nA few years ago I found an amazing project on GitHub called Tube Archivist. It allows you to “Subscribe to your favorite YouTube channels, Download videos, Index and make videos searchable, Play videos, Keep track of viewed and unviewed videos”. Its a great way to save the videos from YouTube that you love just in case they get deleted. Growing up I often heard the saying that “The Internet is Forever” and that stuck with me as a kid. However, now that I am older I know that to not be true. Posts can be deleted, even entire websites. Like we saw with the recent removal of AnandTech’s website archive.\nPlatforms like YouTube are no better. You can find videos that are as old as the platform itself. Which leads people to believe that the content that is uploaded there is there forever. That may be the case for cat videos from 2008. But in recent memory I can recall many of my favorite videos that were taken down for one reason or another. From copyright strikes, retroactive terms of service violations, to even lawsuits. Time has shown that nothing on the internet is guaranteed\nto last. That also goes for TikTok. Which deletes, moderates, and mutes videos frequently. After trying to find a solution similar to Tube Archivist I came up short. So I decided to make a solution myself.\nWhat I ended up with was a python script that uses YT-DLP to download all the videos from the profiles that I specify in a text file. The scrip uses an archive file so that it doesn’t downloads the same video more than once. and much like Tube Archivist it downloads all the videos into folders for each of the profiles that I have “saved”.\nIf I were to start this project over again one thing that I would do differently is use gallery-dl instead of YT-DLP. it is much better at downloading things like pictures as well as videos from a profile.\n\nWindows Auto deployment\n9/19/2025\nLast week I was asked to set up three new windows machines"},"Homelab-Posts/Challenges--and--Lessons-Learned":{"slug":"Homelab-Posts/Challenges--and--Lessons-Learned","filePath":"Homelab Posts/Challenges & Lessons Learned.md","title":"Challenges & Lessons Learned","links":["Homelab"],"tags":[],"content":"I have been tinkering with my server since 2017. In that time I have learned a lot of lessons the hard way. From not backing up data properly, to not testing before committing changes. This page acts as a repo for some of the weirdest and funniest issues that I have encountered.\nAlso check out\nCursed Knowledge by The Immich Team\n“We ran out of columns” by Jimmy Miller\nSoftware Folklore by Andreas Zwinkau\nawesome-bugs  by Julian Berman\n\nQuartz 4 wont delete deleted files\n9/16/25\nThis issue is actuality about updating this very website. When I was first creating the Homelab page I first created a folder called “Homelab” to store sub pages in. But I realized that I cant have a folder and a page with the same name. So I renamed the “Homelab” folder to “Homelab Posts” and then rebuilt the website.  I then found that the “Homelab” page was still a folder for some reason. After several rebuilds that included editing both the quartz.config.ts  and the quartz.layout.ts I found the issue. The /Quartz/public folder does not reflect files that are deleted in /Quartz/content. So after deleting everything in /Quartz/public and building yet again the changes were finally reflected in the built site and I was able to push the changes.\n"},"Homelab-Posts/Core-Services":{"slug":"Homelab-Posts/Core-Services","filePath":"Homelab Posts/Core Services.md","title":"Core Services","links":["Services","Blog-Posts/Accessing-all-my-files-from-every-device"],"tags":[],"content":"The purpose of this page is for me to discuss the services that I have deployed and are now a critical part of my daily life. For a full list of services check out my Services page. I have been running a homelab since 2017 so I have played with a lot of programs and have opinions about the pros and cons of all of them.\n\nQuartz 4\nThis website would be nothing without Quartz. It is what allows me to create a simple website from nothing other than my Obsidian notes.\n\nCaddy\nCaddy is what allows me to serve multiple services from my single residential IP address. A reverse Proxy is something that everyone should play with and know how to use when starting their professional career. I have only scratched the surface of caddy and reverse proxy and hope to get better and learn more as my projects get larger and more ambitious.\n\nUptime Kuma\nThis is yet another amazing open source tool that allows me to monitor the status of all of my services in one dashboard. It will even send me a push notification when one of my services goes offline unexpectedly. It also lets me post a message to my friends when something like the Minecraft server goes offline so I don’t get bombarded with messages  of people asking Hey is XYZ down?.\n\nSyncthing\nI cant praise Syncthing enough. Its one of the longest services that I have been continuously using. Since I got my first serve. It has gotten me through both High school and now College. I have a blog post about Accessing all my files from every device using Syncthing and its a great read for anyone interested in using it.\n\nPiHole\nAbout 2 years ago I gave my PiHole a list of malware and trackers to block and its been super easy to maintain as long as you update the “gravity” (horrible name). One thing that I use it for more than protection is its ability to configure local DNS records extremely easily. It allows me to enter something like NAS.hexadual.lcl in my address bar, file explorer and even NFS mounts."},"Homelab-Posts/Homelab-Evolution":{"slug":"Homelab-Posts/Homelab-Evolution","filePath":"Homelab Posts/Homelab Evolution.md","title":"Homelab Evolution","links":[],"tags":[],"content":""},"Homelab-Posts/Infrastructure-Overview":{"slug":"Homelab-Posts/Infrastructure-Overview","filePath":"Homelab Posts/Infrastructure Overview.md","title":"Infrastructure Overview","links":["Homelab-Posts/Homelab-Evolution","Blog-Posts/Accessing-all-my-files-from-every-device","Services"],"tags":[],"content":"This page discusses the hardware (servers, storage, networking gear, virtualization hosts), Virtualization (VMware, Proxmox, Hyper-V, Docker, Kubernetes), Storage (RAID/ZFS, NAS, backup strategy), and Networking (firewalls, VLANs, NAT, VPN, reverse proxy).\n\n\n                  \n                  Reminder: Last Updated 9/17/2025 \n                  \n                \n\n\nThis page is constantly being updated to reflect the current state of both hardware and software. Check out Homelab Evolution to see the changes that I have made over the years and how I got here.\n\n\n\n\nHardware\nHypervisor\nDell PowerEdge R630 Server\n\nOS: Proxmox\nCPU: 2x E5-2680 V4 - 28 Cores\nRAM: 128GB RAM DDR4\nRAID Controller: H730P\nStorage:\n\n2x 1TB SSD\n6X 1TB WD Black 7200 RPM\n\n\nServices:\n\nHardware virtualization\n\n\n\n\nPlex Server\nCustom Build\n\nOS: Debian\nCPU: Intel Core i5-7600K\nRAM: 2x 4GB DDR4-2133 CL15\nRAID Card: LSI SAS 93​00-16I 12G​B/S HBA\nStorage:\n\n1x Kingston A400 120 GB 2.5” SSD\n1x Western Digital Red 4 TB 3.5” 5400 RPM\n\n\nServices:\n\nPlex\n\n\n\n\nSupermicro\nX9DRi-LN4F+\n\nOS: Fedora\nCPU:\nRAM:\nStorage:\nServices:\n\n\n\n                  \n                  Power \n                  \n                \n\n\nThis machine uses so much energy and puts out so much heat that I rarely use it for anything long term. Its more of a cold spare that I keep around for larger one off projects.\n\n\n\n\nNAS 2.0\nCustom Build\n\nOS: TrueNAS\nCPU: Ryzen 5 5600G\nRAM: 16 GB (2 x 8 GB) DDR4-2400 CL16\nStorage:\n\n5x Western Digital Red 6 TB 3.5” 5400 RPM\n5x Western Digital Red Plus 10 TB 3.5” 7200 RPM\n\n\n\n\nSynology NAS\nDS418\n\nOS: DiskStation Manager (DSM)\nCPU: Realtek RTD1296 quad-core\nRAM: 2 GB DDR4\nStorage:\n\n4x Seagate IronWolf 6TB NAS Hard Drive 7200 RPM\n\n\nServices:\n\nSynology Drive\nSynology Photos\n\n\n\n\nRaspberry Pi #1\nPi 5\n\nOS: DietPi\nCPU: Broadcom BCM2712\nRAM: 8GB\nStorage:\n\n32GB SD Card\n\n\nServices:\n\nJellyfin Live TV\n\n\n\n\nOFF Site Backup\nRaspberry Pi #2\nPi 3 B+\n\nOS: DietPi\nCPU: Broadcom BCM2837B0\nRAM: 1GB LPDDR2\nStorage:\n\n32GB SD Card\n\n\nServices:\n\nOffsite backup. Details TBD\n\n\n\n\nSynology NAS\nDS220+\n\nOS: DiskStation Manager (DSM)\nCPU: Intel Celeron J4025 2-core\nRAM: 2 GB DDR4\nStorage:\n\n2x Seagate IronWolf 6TB NAS Hard Drive 7200 RPM\n\n\n\n\nVirtualization\nCurrently I only have 1 Hypervisor that is has about 10-15 VMs on it at any given time. Some of the VMs handle things like\n\nDocker\nSyncthing\n\nSee “Accessing all my files from every device”\n\n\nPiHole\nGame Servers\nReverse Proxy\nFriends VMs for their projects.\nSee More: Services\n\n\n\n                  \n                   Security through obscurity\n                  \n                \n\n\nI will not go into specifics because I would be making any attackers job easier. Security by obfuscation serves to make reconnaissance from bad actors and unauthorized users harder.\n\n\n\n\nStorage\nNAS 1 and NAS 2 have a combined RAW capacity of 104 Terabytes. However, I use RAID 5 so that reduces the usable storage to 82 Terabytes. There is also a 4TB hard drive in the Plex server that is used for temporary project storage. So the total usable space is 86 Terabytes of useable space.\n\nNetworking\nBy having a wildcard certificate in my DNS records I can direct all traffic from my domain to my reverse proxy server. Personally I use Caddy.So then the proxy server can serve different content from the same IP address.\n"},"Homelab-Posts/Projects--and--Experiments":{"slug":"Homelab-Posts/Projects--and--Experiments","filePath":"Homelab Posts/Projects & Experiments.md","title":"Projects & Experiments","links":["Blog"],"tags":[],"content":"This page is almost redundant due to the fact that I discuss in great detail my projects and experiments on the Blog section of this site. So go check it out."},"Homelab":{"slug":"Homelab","filePath":"Homelab.md","title":"Homelab","links":["Homelab-Posts/Homelab-Evolution","Homelab-Posts/Infrastructure-Overview","Homelab-Posts/Core-Services","Homelab-Posts/Automation--and--Scripting","Homelab-Posts/Projects--and--Experiments","Homelab-Posts/Challenges--and--Lessons-Learned"],"tags":[],"content":"Introduction\nLast updated on: 9/18/2025\nI have been tinkering with my homelab since 2017 when over that summer I built a new computer. Suddenly I had a second perfectly working computer that I didn’t know what to do with. Check out my Homelab Evolution to see the work work that I have done over the years to get to where I am.\nMy Goal with this project is to continuously learn by exploring and creating my own testing/working environments. As well as to experiment with new applications and projects that I find interesting. This helps me stay current and up to date with what is going on in the world of computers and technology at large.\n\nInfrastructure Overview\nThis page discusses the hardware (servers, storage, networking gear, virtualization hosts), Virtualization (VMware, Proxmox, Hyper-V, Docker, Kubernetes), Storage (RAID/ZFS, NAS, backup strategy), and Networking (firewalls, VLANs, NAT, VPN, reverse proxy).\n\nCore Services\nOver the past 9 years I have grown very reliant on some of the services that I have deployed and created. Check out this page to see some of the services that I host and how they help me be productive and stay secure.\n\nAutomation &amp; Scripting\nMany of my personal projects involve scripting and automating things that are tedious and would otherwise take forever. Check out this page for descriptions and documentation on all the things I automate.\n\nProjects &amp; Experiments\nAs it says on the main page of the site. I am always working on something. Sometimes its a simple python scrip. Sometimes its a large ambitus multi month project that takes lots of time and resources. Check out this page for my thoughts on the things that I am working on or plan to work on at some point.\n\nChallenges &amp; Lessons Learned\nI have been tinkering with my server since 2017. In that time I have learned a lot of lessons the hard way. From not backing up data properly, to not testing before committing changes. This page acts as a repo for some of the weirdest and funniest issues that I have encountered."},"Resume":{"slug":"Resume","filePath":"Resume.md","title":"Resume","links":[],"tags":[],"content":"\n\n\n                  \n                  Info\n                  \n                \n\n\nResume last updated 8/12/25\nDownload\n\n\n\n\nCertifications\nArtificial Intelligence Fundamentals\n\n\n\n                  \n                  Summary\n                  \n                \n\n\nThis credential earner demonstrates knowledge of artificial intelligence (AI) concepts, such as natural language processing, computer vision, machine learning, deep learning, chatbots, and neural networks; AI ethics; and the applications of AI. The individual has a conceptual understanding of how to run an AI model using IBM Watson Studio. The earner is aware of the job outlook in fields that use AI and is familiar with the skills required for success in various roles in the domain.\n\n\n"},"Services":{"slug":"Services","filePath":"Services.md","title":"Services","links":[],"tags":[],"content":"File Share\nQuickly send and embed small files\n\nYouTube Archive\nYouTube Video Archive\n\nSlop Toob\nLive TV but its all slop\n\nFile Drive\nBackup storage for files\n\nLive Stream\nThe stream may break but the fun is guaranteed!!\n\nCOVID Epoch Time\nSeconds since March 13, 2020\n\nFood Database\nFind out what I’m cooing\n\nStatus Page\n\n*Updates in real time*"},"index":{"slug":"index","filePath":"index.md","title":"index","links":["Blog","Homelab","Resume","Services"],"tags":[],"content":"Welcome\nHi, I’m Jacob — a recent Purdue University graduate with a degree in Cybersecurity.\nI’m passionate about technology, lifelong learning, and applying what I learn to real-world projects in my homelab. This site is where I share my thoughts, experiments, and experience—both academic and hands-on.\n\n\nCurrent Projects\nI am always working on something!\nFind out more on my Blog or check out my Homelab documentation.\n\nMy Resume\nCurious about my background, skills, or experience?\nCheck out my Resume.\n\nContact Me\nOn LinkedIn\nor by email: Jacob@Hexadual.io\n\nCheck out my Services\nOr check if something is wrong with the Status Page\n\nCheck out what I’ve been listening to\n\n  \n"}}